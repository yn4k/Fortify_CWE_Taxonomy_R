<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf8">
<title>Software Security | Protect your Software at the Source | HPE Security Fortify</title>
<link rel="stylesheet" href="../css/vcmain.css" type="text/css" media="screen" title="no title" charset="utf-8">
</head>
<script language="javascript">

					if (top.location == self.location)
					{ //if page is not in its frameset
					//top.location.href = "/vulncat/index.html?open=" + window.location.href;
					}

				</script><!-- End of document.header.tile --><body class="level3"><div id="theWrapper">
						<div id="theContentCenter">
							<!-- desc.dataflow.java.hadoop_job_manipulation -->						
							<h1>
							   Hadoop Job Manipulation
							</h1>
							<h2>ABSTRACT</h2>
							<p>
							  The <code>Job</code> submitted to a Hadoop cluster can be tampered in a hostile environment.
							</p>
							<h2>EXPLANATION</h2>
							<p>
							  Hadoop job manipulation errors occur when:<br><br>- Data enters a program from an untrusted source.<br><br>- The data is used to specify a value of the <code>JobConf</code> that controls a client job.<br><br>Hadoop clusters are a hostile environment. When security configurations from protecting unauthorized access to HDFS on cluster machines are not set properly, an attack may be able to take control. This leads to the possibility that any data that is provided by the Hadoop cluster is tampered.<br><br><b>Example 1:</b> The following code shows a <code>Job</code> submission in a typical client application which takes inputs from command line on Hadoop cluster master machine:<br><br></p>
<pre><br>  public void run(String args[]) throws IOException {<br><br>    String inputDir = args[0];<br>    String outputDir = args[1];<br><br>    // Untrusted command line argument<br>    int numOfReducers = Integer.parseInt(args[3]);<br>    Class mapper = getClassByName(args[4]);<br>    Class reducer = getClassByName(args[5]);<br><br>    Configuration defaults = new Configuration();<br>    JobConf job = new JobConf(defaults, OptimizedDataJoinJob.class);<br>    job.setNumMapTasks(1);<br>    // An attacker may set random values that exceed the range of acceptable number of reducers<br>    job.setNumReduceTasks(numOfReducers);<br><br>    return job;<br>  }<br></pre>
<br><br><b>Example 2:</b> The following code shows a case where an attacker controls the running job to be killed through command line arguments:<br><br><pre><br>  public static void main(String[] args) throws Exception {<br><br>    JobID id = JobID.forName(args[0]);<br>    JobConf conf = new JobConf(WordCount.class);<br>    // configure this JobConf instance<br>    ...<br>    JobClient.runJob(conf);<br>    RunningJob job = JobClient.getJob(id);<br>    job.killJob();<br><br>  }<br></pre>
							
							 								<h2>REFERENCES</h2>
																								   <p>[1]  <em>INPUT-1: Validate inputs</em> Oracle<br></p>
																									   <p>[2] Standards Mapping - NIST Special Publication 800-53 Revision 4 <em>SI-10 Information Input Validation (P1)</em> <br></p>
																									   <p>[3] Standards Mapping - OWASP Top 10 2004 <em>A1 Unvalidated Input</em> <br></p>
																									   <p>[4] Standards Mapping - Payment Card Industry Data Security Standard Version 3.0 <em>Requirement 6.5.1</em> <br></p>
																									   <p>[5] Standards Mapping - Payment Card Industry Data Security Standard Version 3.1 <em>Requirement 6.5.1</em> <br></p>
																									   <p>[6] Standards Mapping - Web Application Security Consortium Version 2.00 <em>Improper Input Handling (WASC-20)</em> <br></p>
																														<div id="theFooter">
							<p></p>
							<br><center>
                                                        Â© Copyright 2008 - 2015 Hewlett Packard Enterprise Development Company, L.P.
							<br>
							(Generated from version 2015.4.0.0008 of the HPE Security Fortify Secure Coding Rulepacks)
							<br>
							desc.dataflow.java.hadoop_job_manipulation
							</center>
							<p></p>
						</div>
</div>
</div></body>
</html>
 
